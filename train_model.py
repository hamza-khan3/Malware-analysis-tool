import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

def load_and_preprocess_data(file_path):
    df = pd.read_csv(file_path)
    X = df.drop('Label', axis=1)
    y = df['Label'].apply(lambda x: 1 if x == 'Malicious' else 0)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    return X_train, X_test, y_train, y_test

def build_keras_model():
    model = Sequential([
        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        Dropout(0.5),
        Dense(32, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
    return model

def experiment_with_ensemble(X_train, y_train, X_test, y_test):
    rf = RandomForestClassifier(n_estimators=50, random_state=1)
    lr = LogisticRegression()
    svm = SVC(probability=True)
    nn = KerasClassifier(build_fn=build_keras_model, epochs=20, batch_size=32, verbose=0)

    ensemble = VotingClassifier(estimators=[
        ('rf', rf), ('lr', lr), ('svm', svm), ('nn', nn)
    ], voting='soft')

    ensemble.fit(X_train, y_train)
    predictions = ensemble.predict(X_test)
    print("Ensemble Classification Report:")
    print(classification_report(y_test, predictions))

def plot_history(history):
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')
    plt.show()

    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')
    plt.show()

def main():
    file_path = 'malware_features.csv'
    X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path)
    
    # Experiment with ensemble models
    experiment_with_ensemble(X_train, y_train, X_test, y_test)
    
    # If you still want to train the Keras model independently, you can do so here:
    # model, history = build_and_train_model(X_train, y_train, X_test, y_test)
    # plot_history(history)
    # model.save('malware_model.h5')
    # print("Model training completed and saved as 'malware_model.h5'.")

if __name__ == "__main__":
    main()
